{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial of adversarial debiasing combined with optimized preprocessing to mitigate bias and retain accurac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Preprocessing: Objective converged to 0.015890\n"
     ]
    }
   ],
   "source": [
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "    \n",
    "OP = OptimPreproc(OptTools, optim_options)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "dataset_transf_train = OP.transform(dataset_orig_train, transform_Y=True)\n",
    "\n",
    "dataset_transf_train = dataset_orig_train.align_datasets(dataset_transf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.195668\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.191853\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.195668\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.191853\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:133: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:82: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:155: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:157: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From ../aif360/algorithms/inprocessing/adversarial_debiasing.py:182: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772482\n",
      "epoch 0; iter: 200; batch classifier loss: 0.489046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.414704\n",
      "epoch 1; iter: 200; batch classifier loss: 0.465397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406299\n",
      "epoch 2; iter: 200; batch classifier loss: 0.354217\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427093\n",
      "epoch 3; iter: 200; batch classifier loss: 0.386823\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528085\n",
      "epoch 4; iter: 200; batch classifier loss: 0.439163\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362157\n",
      "epoch 5; iter: 200; batch classifier loss: 0.415463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402527\n",
      "epoch 6; iter: 200; batch classifier loss: 0.386667\n",
      "epoch 7; iter: 0; batch classifier loss: 0.407469\n",
      "epoch 7; iter: 200; batch classifier loss: 0.434790\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494160\n",
      "epoch 8; iter: 200; batch classifier loss: 0.372066\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418530\n",
      "epoch 9; iter: 200; batch classifier loss: 0.412396\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375445\n",
      "epoch 10; iter: 200; batch classifier loss: 0.388955\n",
      "epoch 11; iter: 0; batch classifier loss: 0.378593\n",
      "epoch 11; iter: 200; batch classifier loss: 0.454740\n",
      "epoch 12; iter: 0; batch classifier loss: 0.393414\n",
      "epoch 12; iter: 200; batch classifier loss: 0.388493\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455661\n",
      "epoch 13; iter: 200; batch classifier loss: 0.469559\n",
      "epoch 14; iter: 0; batch classifier loss: 0.411532\n",
      "epoch 14; iter: 200; batch classifier loss: 0.418876\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361011\n",
      "epoch 15; iter: 200; batch classifier loss: 0.485222\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377332\n",
      "epoch 16; iter: 200; batch classifier loss: 0.339853\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480876\n",
      "epoch 17; iter: 200; batch classifier loss: 0.468178\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439851\n",
      "epoch 18; iter: 200; batch classifier loss: 0.483209\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444823\n",
      "epoch 19; iter: 200; batch classifier loss: 0.377787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.392642\n",
      "epoch 20; iter: 200; batch classifier loss: 0.365063\n",
      "epoch 21; iter: 0; batch classifier loss: 0.451436\n",
      "epoch 21; iter: 200; batch classifier loss: 0.347016\n",
      "epoch 22; iter: 0; batch classifier loss: 0.340248\n",
      "epoch 22; iter: 200; batch classifier loss: 0.414466\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452312\n",
      "epoch 23; iter: 200; batch classifier loss: 0.416463\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494910\n",
      "epoch 24; iter: 200; batch classifier loss: 0.461984\n",
      "epoch 25; iter: 0; batch classifier loss: 0.365494\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360525\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460949\n",
      "epoch 26; iter: 200; batch classifier loss: 0.436627\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460839\n",
      "epoch 27; iter: 200; batch classifier loss: 0.438163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404894\n",
      "epoch 28; iter: 200; batch classifier loss: 0.445732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448413\n",
      "epoch 29; iter: 200; batch classifier loss: 0.480269\n",
      "epoch 30; iter: 0; batch classifier loss: 0.359265\n",
      "epoch 30; iter: 200; batch classifier loss: 0.464796\n",
      "epoch 31; iter: 0; batch classifier loss: 0.375484\n",
      "epoch 31; iter: 200; batch classifier loss: 0.426094\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526398\n",
      "epoch 32; iter: 200; batch classifier loss: 0.427447\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437544\n",
      "epoch 33; iter: 200; batch classifier loss: 0.441203\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432180\n",
      "epoch 34; iter: 200; batch classifier loss: 0.386361\n",
      "epoch 35; iter: 0; batch classifier loss: 0.358383\n",
      "epoch 35; iter: 200; batch classifier loss: 0.430976\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481939\n",
      "epoch 36; iter: 200; batch classifier loss: 0.378586\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474039\n",
      "epoch 37; iter: 200; batch classifier loss: 0.388066\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407259\n",
      "epoch 38; iter: 200; batch classifier loss: 0.413250\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430203\n",
      "epoch 39; iter: 200; batch classifier loss: 0.451575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.388032\n",
      "epoch 40; iter: 200; batch classifier loss: 0.343962\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410717\n",
      "epoch 41; iter: 200; batch classifier loss: 0.493100\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454102\n",
      "epoch 42; iter: 200; batch classifier loss: 0.367802\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456034\n",
      "epoch 43; iter: 200; batch classifier loss: 0.415213\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388866\n",
      "epoch 44; iter: 200; batch classifier loss: 0.382947\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372523\n",
      "epoch 45; iter: 200; batch classifier loss: 0.342624\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463622\n",
      "epoch 46; iter: 200; batch classifier loss: 0.416287\n",
      "epoch 47; iter: 0; batch classifier loss: 0.454832\n",
      "epoch 47; iter: 200; batch classifier loss: 0.394164\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403533\n",
      "epoch 48; iter: 200; batch classifier loss: 0.439484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447964\n",
      "epoch 49; iter: 200; batch classifier loss: 0.388107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x13fe18fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.238627\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.231134\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.805569\n",
      "Test set: Balanced classification accuracy = 0.673387\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.493298\n",
      "Test set: Average odds difference = -0.305651\n",
      "Test set: Theil_index = 0.170900\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.669689; batch adversarial loss: 0.596862\n",
      "epoch 0; iter: 200; batch classifier loss: 0.441485; batch adversarial loss: 0.649003\n",
      "epoch 1; iter: 0; batch classifier loss: 0.521617; batch adversarial loss: 0.639258\n",
      "epoch 1; iter: 200; batch classifier loss: 0.498241; batch adversarial loss: 0.680808\n",
      "epoch 2; iter: 0; batch classifier loss: 0.470847; batch adversarial loss: 0.650181\n",
      "epoch 2; iter: 200; batch classifier loss: 0.423797; batch adversarial loss: 0.687070\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400263; batch adversarial loss: 0.626102\n",
      "epoch 3; iter: 200; batch classifier loss: 0.451076; batch adversarial loss: 0.658149\n",
      "epoch 4; iter: 0; batch classifier loss: 0.507348; batch adversarial loss: 0.538149\n",
      "epoch 4; iter: 200; batch classifier loss: 0.423147; batch adversarial loss: 0.584343\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387952; batch adversarial loss: 0.566659\n",
      "epoch 5; iter: 200; batch classifier loss: 0.402351; batch adversarial loss: 0.578057\n",
      "epoch 6; iter: 0; batch classifier loss: 0.425619; batch adversarial loss: 0.610345\n",
      "epoch 6; iter: 200; batch classifier loss: 0.505207; batch adversarial loss: 0.619696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379647; batch adversarial loss: 0.613770\n",
      "epoch 7; iter: 200; batch classifier loss: 0.472146; batch adversarial loss: 0.600706\n",
      "epoch 8; iter: 0; batch classifier loss: 0.422265; batch adversarial loss: 0.627426\n",
      "epoch 8; iter: 200; batch classifier loss: 0.455876; batch adversarial loss: 0.654571\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458057; batch adversarial loss: 0.634514\n",
      "epoch 9; iter: 200; batch classifier loss: 0.389145; batch adversarial loss: 0.612123\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440003; batch adversarial loss: 0.574966\n",
      "epoch 10; iter: 200; batch classifier loss: 0.365469; batch adversarial loss: 0.600026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361550; batch adversarial loss: 0.642404\n",
      "epoch 11; iter: 200; batch classifier loss: 0.455325; batch adversarial loss: 0.623555\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397686; batch adversarial loss: 0.582746\n",
      "epoch 12; iter: 200; batch classifier loss: 0.476898; batch adversarial loss: 0.546210\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432520; batch adversarial loss: 0.580548\n",
      "epoch 13; iter: 200; batch classifier loss: 0.495546; batch adversarial loss: 0.514385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438587; batch adversarial loss: 0.623683\n",
      "epoch 14; iter: 200; batch classifier loss: 0.363301; batch adversarial loss: 0.641085\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438028; batch adversarial loss: 0.628695\n",
      "epoch 15; iter: 200; batch classifier loss: 0.456902; batch adversarial loss: 0.595963\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396105; batch adversarial loss: 0.581333\n",
      "epoch 16; iter: 200; batch classifier loss: 0.433715; batch adversarial loss: 0.669642\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479511; batch adversarial loss: 0.627155\n",
      "epoch 17; iter: 200; batch classifier loss: 0.425252; batch adversarial loss: 0.626938\n",
      "epoch 18; iter: 0; batch classifier loss: 0.413965; batch adversarial loss: 0.613604\n",
      "epoch 18; iter: 200; batch classifier loss: 0.472300; batch adversarial loss: 0.617220\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457627; batch adversarial loss: 0.559247\n",
      "epoch 19; iter: 200; batch classifier loss: 0.444898; batch adversarial loss: 0.634932\n",
      "epoch 20; iter: 0; batch classifier loss: 0.423151; batch adversarial loss: 0.589603\n",
      "epoch 20; iter: 200; batch classifier loss: 0.464358; batch adversarial loss: 0.574454\n",
      "epoch 21; iter: 0; batch classifier loss: 0.384925; batch adversarial loss: 0.600170\n",
      "epoch 21; iter: 200; batch classifier loss: 0.455270; batch adversarial loss: 0.553690\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350328; batch adversarial loss: 0.629880\n",
      "epoch 22; iter: 200; batch classifier loss: 0.347668; batch adversarial loss: 0.657942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.375071; batch adversarial loss: 0.636693\n",
      "epoch 23; iter: 200; batch classifier loss: 0.434998; batch adversarial loss: 0.558897\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505679; batch adversarial loss: 0.595664\n",
      "epoch 24; iter: 200; batch classifier loss: 0.455256; batch adversarial loss: 0.620074\n",
      "epoch 25; iter: 0; batch classifier loss: 0.391573; batch adversarial loss: 0.636729\n",
      "epoch 25; iter: 200; batch classifier loss: 0.499847; batch adversarial loss: 0.673927\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479101; batch adversarial loss: 0.595941\n",
      "epoch 26; iter: 200; batch classifier loss: 0.411546; batch adversarial loss: 0.547426\n",
      "epoch 27; iter: 0; batch classifier loss: 0.549100; batch adversarial loss: 0.684338\n",
      "epoch 27; iter: 200; batch classifier loss: 0.435164; batch adversarial loss: 0.581594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507052; batch adversarial loss: 0.561724\n",
      "epoch 28; iter: 200; batch classifier loss: 0.321616; batch adversarial loss: 0.611229\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342857; batch adversarial loss: 0.594788\n",
      "epoch 29; iter: 200; batch classifier loss: 0.427327; batch adversarial loss: 0.583301\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514900; batch adversarial loss: 0.604093\n",
      "epoch 30; iter: 200; batch classifier loss: 0.431120; batch adversarial loss: 0.568404\n",
      "epoch 31; iter: 0; batch classifier loss: 0.395246; batch adversarial loss: 0.576029\n",
      "epoch 31; iter: 200; batch classifier loss: 0.417429; batch adversarial loss: 0.565512\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473480; batch adversarial loss: 0.591262\n",
      "epoch 32; iter: 200; batch classifier loss: 0.500118; batch adversarial loss: 0.610620\n",
      "epoch 33; iter: 0; batch classifier loss: 0.389829; batch adversarial loss: 0.648145\n",
      "epoch 33; iter: 200; batch classifier loss: 0.527174; batch adversarial loss: 0.626354\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453033; batch adversarial loss: 0.629618\n",
      "epoch 34; iter: 200; batch classifier loss: 0.404705; batch adversarial loss: 0.593928\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444552; batch adversarial loss: 0.646255\n",
      "epoch 35; iter: 200; batch classifier loss: 0.410228; batch adversarial loss: 0.579169\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406875; batch adversarial loss: 0.590338\n",
      "epoch 36; iter: 200; batch classifier loss: 0.436916; batch adversarial loss: 0.634356\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435969; batch adversarial loss: 0.621034\n",
      "epoch 37; iter: 200; batch classifier loss: 0.387605; batch adversarial loss: 0.661952\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437653; batch adversarial loss: 0.581594\n",
      "epoch 38; iter: 200; batch classifier loss: 0.549368; batch adversarial loss: 0.614515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.391687; batch adversarial loss: 0.604977\n",
      "epoch 39; iter: 200; batch classifier loss: 0.540239; batch adversarial loss: 0.556288\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372142; batch adversarial loss: 0.607834\n",
      "epoch 40; iter: 200; batch classifier loss: 0.353620; batch adversarial loss: 0.618101\n",
      "epoch 41; iter: 0; batch classifier loss: 0.531454; batch adversarial loss: 0.612889\n",
      "epoch 41; iter: 200; batch classifier loss: 0.523146; batch adversarial loss: 0.682361\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452511; batch adversarial loss: 0.610049\n",
      "epoch 42; iter: 200; batch classifier loss: 0.479618; batch adversarial loss: 0.589830\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419818; batch adversarial loss: 0.626135\n",
      "epoch 43; iter: 200; batch classifier loss: 0.433207; batch adversarial loss: 0.669597\n",
      "epoch 44; iter: 0; batch classifier loss: 0.487622; batch adversarial loss: 0.651168\n",
      "epoch 44; iter: 200; batch classifier loss: 0.477583; batch adversarial loss: 0.637336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412143; batch adversarial loss: 0.625023\n",
      "epoch 45; iter: 200; batch classifier loss: 0.407012; batch adversarial loss: 0.624977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469155; batch adversarial loss: 0.651579\n",
      "epoch 46; iter: 200; batch classifier loss: 0.566069; batch adversarial loss: 0.669348\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424129; batch adversarial loss: 0.632132\n",
      "epoch 47; iter: 200; batch classifier loss: 0.479071; batch adversarial loss: 0.622983\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474085; batch adversarial loss: 0.620416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 200; batch classifier loss: 0.426208; batch adversarial loss: 0.589269\n",
      "epoch 49; iter: 0; batch classifier loss: 0.500520; batch adversarial loss: 0.587509\n",
      "epoch 49; iter: 200; batch classifier loss: 0.375048; batch adversarial loss: 0.582769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x147df0198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.238627\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.231134\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.078679\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.070891\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.805569\n",
      "Test set: Balanced classification accuracy = 0.673387\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.493298\n",
      "Test set: Average odds difference = -0.305651\n",
      "Test set: Theil_index = 0.170900\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.794581\n",
      "Test set: Balanced classification accuracy = 0.672817\n",
      "Test set: Disparate impact = 0.644505\n",
      "Test set: Equal opportunity difference = -0.033621\n",
      "Test set: Average odds difference = -0.016772\n",
      "Test set: Theil_index = 0.170332\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    References:\n",
    "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
    "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
