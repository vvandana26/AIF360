{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in healthcare utilization scoring model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Reference - https://nbviewer.jupyter.org/github/IBM/AIF360/blob/master/examples/tutorial_medical_expenditure.ipynb\n",
    "    </b>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This tutorial demonstrates classification model learning with bias mitigation as a part of a Care Management use case using Medical Expenditure data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook demonstrates how the AIF 360 toolkit can be used to detect and reduce bias when learning classifiers using a variety of fairness metrics and algorithms . It also demonstrates how explanations can be generated for predictions made by models learnt with the toolkit using LIME.\n",
    "\n",
    "Classifiers are built using Logistic Regression as well as Random Forests.\n",
    "\n",
    "Bias detection is demonstrated using several metrics, including disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index.\n",
    "\n",
    "Bias alleviation is explored via a variety of methods, including reweighing (pre-processing algorithm), prejudice remover (in-processing algorithm), and disparate impact remover (pre-processing technique).\n",
    "\n",
    "Data from the [Medical Expenditure Panel Survey](https://meps.ahrq.gov/mepsweb/) is used in this tutorial. See [Section 2](#2.-Data-used) below for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.](#Table-of-Contents) Use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to demonstrate how AIF 360 can be used to detect and mitigate bias in classfier models, we adopt the following use case:\n",
    "\n",
    "1. a data scientist develops a 'fair' healthcare utilization scoring model with respect to defined protected classes. Fairness may be dictated by legal or government regulations, such as a requirement that additional care decisions be not predicated on factors such as race of the patient.\n",
    "\n",
    "\n",
    "2. developer takes the model AND performance characteristics / specs of the model (e.g. accuracy, fairness tests, etc. basically the model factsheet) and deploys the model in an enterprise app that prioritizes cases for care management.\n",
    "\n",
    "\n",
    "3. the app is put into production and starts scoring people and making recommendations. \n",
    "\n",
    "\n",
    "4. explanations are generated for each recommendation\n",
    "\n",
    "\n",
    "5. both recommendations and associated explanations are given to nurses as a part of the care management process. The nurses can evaluate the recommendations for quality and correctness and provide feedback.\n",
    "\n",
    "\n",
    "6. nurse feedback as well as analysis of usage data with respect to specs of the model w.r.t accuracy and fairness is communicated to AI Ops specialist and LOB user periodically.\n",
    "\n",
    "\n",
    "7. when significant drift in model specs relative to the model factsheet is observed, the model is sent back for retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2.](#Table-of-Contents) Data used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "For this demonstration, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.](#Table-of-Contents) Training models on original 2015 Panel 19 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load data & create splits for learning/validating/testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset and split into train (70%), test (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhanush/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/aif360/datasets/standard_dataset.py:121: FutureWarning: outer method for ufunc <ufunc 'equal'> is not implemented on pandas objects. Returning an ndarray, but in the future this will raise a 'NotImplementedError'. Consider explicitly converting the Series to an array with '.array' first.\n",
      "  priv = np.logical_or.reduce(np.equal.outer(vals, df[attr]))\n"
     ]
    }
   ],
   "source": [
    "(dataset_orig_panel19_train,\n",
    " dataset_orig_panel19_test) = MEPSDataset19().split([0.7], shuffle=True)\n",
    "\n",
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "\n",
    "unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used throughout the notebook to print out some labels, names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def describe(train=None, val=None, test=None):\n",
    "    if train is not None:\n",
    "        display(Markdown(\"#### Training Dataset shape\"))\n",
    "        print(train.features.shape)\n",
    "    if val is not None:\n",
    "        display(Markdown(\"#### Validation Dataset shape\"))\n",
    "        print(val.features.shape)\n",
    "    display(Markdown(\"#### Test Dataset shape\"))\n",
    "    print(test.features.shape)\n",
    "    display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "    print(test.favorable_label, test.unfavorable_label)\n",
    "    display(Markdown(\"#### Protected attribute names\"))\n",
    "    print(test.protected_attribute_names)\n",
    "    display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "    print(test.privileged_protected_attributes, \n",
    "          test.unprivileged_protected_attributes)\n",
    "    display(Markdown(\"#### Dataset feature names\"))\n",
    "    print(test.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show 2015 dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11081, 138)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4749, 138)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RACE']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE', 'RACE', 'PCS42', 'MCS42', 'K6SUM42', 'REGION=1', 'REGION=2', 'REGION=3', 'REGION=4', 'SEX=1', 'SEX=2', 'MARRY=1', 'MARRY=2', 'MARRY=3', 'MARRY=4', 'MARRY=5', 'MARRY=6', 'MARRY=7', 'MARRY=8', 'MARRY=9', 'MARRY=10', 'FTSTU=-1', 'FTSTU=1', 'FTSTU=2', 'FTSTU=3', 'ACTDTY=1', 'ACTDTY=2', 'ACTDTY=3', 'ACTDTY=4', 'HONRDC=1', 'HONRDC=2', 'HONRDC=3', 'HONRDC=4', 'RTHLTH=-1', 'RTHLTH=1', 'RTHLTH=2', 'RTHLTH=3', 'RTHLTH=4', 'RTHLTH=5', 'MNHLTH=-1', 'MNHLTH=1', 'MNHLTH=2', 'MNHLTH=3', 'MNHLTH=4', 'MNHLTH=5', 'HIBPDX=-1', 'HIBPDX=1', 'HIBPDX=2', 'CHDDX=-1', 'CHDDX=1', 'CHDDX=2', 'ANGIDX=-1', 'ANGIDX=1', 'ANGIDX=2', 'MIDX=-1', 'MIDX=1', 'MIDX=2', 'OHRTDX=-1', 'OHRTDX=1', 'OHRTDX=2', 'STRKDX=-1', 'STRKDX=1', 'STRKDX=2', 'EMPHDX=-1', 'EMPHDX=1', 'EMPHDX=2', 'CHBRON=-1', 'CHBRON=1', 'CHBRON=2', 'CHOLDX=-1', 'CHOLDX=1', 'CHOLDX=2', 'CANCERDX=-1', 'CANCERDX=1', 'CANCERDX=2', 'DIABDX=-1', 'DIABDX=1', 'DIABDX=2', 'JTPAIN=-1', 'JTPAIN=1', 'JTPAIN=2', 'ARTHDX=-1', 'ARTHDX=1', 'ARTHDX=2', 'ARTHTYPE=-1', 'ARTHTYPE=1', 'ARTHTYPE=2', 'ARTHTYPE=3', 'ASTHDX=1', 'ASTHDX=2', 'ADHDADDX=-1', 'ADHDADDX=1', 'ADHDADDX=2', 'PREGNT=-1', 'PREGNT=1', 'PREGNT=2', 'WLKLIM=-1', 'WLKLIM=1', 'WLKLIM=2', 'ACTLIM=-1', 'ACTLIM=1', 'ACTLIM=2', 'SOCLIM=-1', 'SOCLIM=1', 'SOCLIM=2', 'COGLIM=-1', 'COGLIM=1', 'COGLIM=2', 'DFHEAR42=-1', 'DFHEAR42=1', 'DFHEAR42=2', 'DFSEE42=-1', 'DFSEE42=1', 'DFSEE42=2', 'ADSMOK42=-1', 'ADSMOK42=1', 'ADSMOK42=2', 'PHQ242=-1', 'PHQ242=0', 'PHQ242=1', 'PHQ242=2', 'PHQ242=3', 'PHQ242=4', 'PHQ242=5', 'PHQ242=6', 'EMPST=-1', 'EMPST=1', 'EMPST=2', 'EMPST=3', 'EMPST=4', 'POVCAT=1', 'POVCAT=2', 'POVCAT=3', 'POVCAT=4', 'POVCAT=5', 'INSCOV=1', 'INSCOV=2', 'INSCOV=3']\n"
     ]
    }
   ],
   "source": [
    "describe(dataset_orig_panel19_train, None, dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.5062355260737379\n"
     ]
    }
   ],
   "source": [
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "        dataset_orig_panel19_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)\n",
    "explainer_orig_panel19_train = MetricTextExplainer(metric_orig_panel19_train)\n",
    "\n",
    "print(explainer_orig_panel19_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Debiasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.133492\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.138635\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_panel19_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_panel19_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.133492\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.138635\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_panel19_train.features = min_max_scaler.fit_transform(dataset_orig_panel19_train.features)\n",
    "dataset_orig_panel19_test.features = min_max_scaler.transform(dataset_orig_panel19_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_panel19_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_panel19_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.595445; batch adversarial loss: 0.708192\n",
      "epoch 1; iter: 0; batch classifier loss: 0.343685; batch adversarial loss: 0.685541\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369257; batch adversarial loss: 0.679864\n",
      "epoch 3; iter: 0; batch classifier loss: 0.319929; batch adversarial loss: 0.669934\n",
      "epoch 4; iter: 0; batch classifier loss: 0.408852; batch adversarial loss: 0.657711\n",
      "epoch 5; iter: 0; batch classifier loss: 0.385198; batch adversarial loss: 0.655831\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348530; batch adversarial loss: 0.642233\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312382; batch adversarial loss: 0.661296\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297410; batch adversarial loss: 0.659129\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314212; batch adversarial loss: 0.647203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291192; batch adversarial loss: 0.653255\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372638; batch adversarial loss: 0.648143\n",
      "epoch 12; iter: 0; batch classifier loss: 0.319021; batch adversarial loss: 0.624806\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273337; batch adversarial loss: 0.648904\n",
      "epoch 14; iter: 0; batch classifier loss: 0.253349; batch adversarial loss: 0.634443\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247601; batch adversarial loss: 0.606553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243130; batch adversarial loss: 0.626893\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285639; batch adversarial loss: 0.631236\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268704; batch adversarial loss: 0.617035\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337489; batch adversarial loss: 0.702434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273179; batch adversarial loss: 0.684620\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243272; batch adversarial loss: 0.619492\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193797; batch adversarial loss: 0.601720\n",
      "epoch 23; iter: 0; batch classifier loss: 0.302248; batch adversarial loss: 0.655566\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230757; batch adversarial loss: 0.626007\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291459; batch adversarial loss: 0.696171\n",
      "epoch 26; iter: 0; batch classifier loss: 0.255738; batch adversarial loss: 0.614258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.281795; batch adversarial loss: 0.626422\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236439; batch adversarial loss: 0.616105\n",
      "epoch 29; iter: 0; batch classifier loss: 0.254527; batch adversarial loss: 0.676705\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390991; batch adversarial loss: 0.634573\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283948; batch adversarial loss: 0.653506\n",
      "epoch 32; iter: 0; batch classifier loss: 0.278940; batch adversarial loss: 0.708002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275877; batch adversarial loss: 0.646129\n",
      "epoch 34; iter: 0; batch classifier loss: 0.213655; batch adversarial loss: 0.708395\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293472; batch adversarial loss: 0.652874\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257185; batch adversarial loss: 0.667260\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277636; batch adversarial loss: 0.652897\n",
      "epoch 38; iter: 0; batch classifier loss: 0.251467; batch adversarial loss: 0.643653\n",
      "epoch 39; iter: 0; batch classifier loss: 0.235045; batch adversarial loss: 0.590622\n",
      "epoch 40; iter: 0; batch classifier loss: 0.176064; batch adversarial loss: 0.645554\n",
      "epoch 41; iter: 0; batch classifier loss: 0.258981; batch adversarial loss: 0.651292\n",
      "epoch 42; iter: 0; batch classifier loss: 0.211716; batch adversarial loss: 0.641892\n",
      "epoch 43; iter: 0; batch classifier loss: 0.196834; batch adversarial loss: 0.619369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136030; batch adversarial loss: 0.604650\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199715; batch adversarial loss: 0.631398\n",
      "epoch 46; iter: 0; batch classifier loss: 0.231392; batch adversarial loss: 0.653319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.196196; batch adversarial loss: 0.675920\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266193; batch adversarial loss: 0.669669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.178949; batch adversarial loss: 0.697529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x1315f0e10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.821947\n",
      "Test set: Balanced classification accuracy = 0.700171\n",
      "Test set: Disparate impact = 0.565905\n",
      "Test set: Equal opportunity difference = -0.045146\n",
      "Test set: Average odds difference = -0.040512\n",
      "Test set: Statistical parity difference = -0.091879\n",
      "Test set: Theil_index = 0.112782\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from model with debiasing\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_panel19_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_debiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Debiasing with weighted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_panel19_train = RW.fit_transform(dataset_orig_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Metric for the transformed dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_transf_panel19_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# Learn parameters with debias set to True\n",
    "weighted_debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.704628; batch adversarial loss: 0.753521\n",
      "epoch 1; iter: 0; batch classifier loss: 0.363869; batch adversarial loss: 0.694662\n",
      "epoch 2; iter: 0; batch classifier loss: 0.253869; batch adversarial loss: 0.680370\n",
      "epoch 3; iter: 0; batch classifier loss: 0.309635; batch adversarial loss: 0.667766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303630; batch adversarial loss: 0.663555\n",
      "epoch 5; iter: 0; batch classifier loss: 0.300757; batch adversarial loss: 0.658754\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330101; batch adversarial loss: 0.658806\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352510; batch adversarial loss: 0.684398\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230057; batch adversarial loss: 0.628915\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432744; batch adversarial loss: 0.659590\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255797; batch adversarial loss: 0.635037\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237745; batch adversarial loss: 0.641151\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379109; batch adversarial loss: 0.656645\n",
      "epoch 13; iter: 0; batch classifier loss: 0.303031; batch adversarial loss: 0.621681\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257138; batch adversarial loss: 0.668087\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350657; batch adversarial loss: 0.649379\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303448; batch adversarial loss: 0.668540\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243596; batch adversarial loss: 0.655965\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241435; batch adversarial loss: 0.626234\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317073; batch adversarial loss: 0.655432\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295384; batch adversarial loss: 0.664418\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267132; batch adversarial loss: 0.629092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242301; batch adversarial loss: 0.623897\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184650; batch adversarial loss: 0.638187\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233296; batch adversarial loss: 0.655275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234160; batch adversarial loss: 0.615939\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319753; batch adversarial loss: 0.627013\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239821; batch adversarial loss: 0.637075\n",
      "epoch 28; iter: 0; batch classifier loss: 0.330633; batch adversarial loss: 0.637121\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263169; batch adversarial loss: 0.685801\n",
      "epoch 30; iter: 0; batch classifier loss: 0.295962; batch adversarial loss: 0.661507\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268063; batch adversarial loss: 0.627959\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247443; batch adversarial loss: 0.604807\n",
      "epoch 33; iter: 0; batch classifier loss: 0.252318; batch adversarial loss: 0.638920\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220342; batch adversarial loss: 0.640174\n",
      "epoch 35; iter: 0; batch classifier loss: 0.246188; batch adversarial loss: 0.612560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.388828; batch adversarial loss: 0.625678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.278201; batch adversarial loss: 0.690762\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207307; batch adversarial loss: 0.652850\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207968; batch adversarial loss: 0.635524\n",
      "epoch 40; iter: 0; batch classifier loss: 0.199936; batch adversarial loss: 0.701586\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248852; batch adversarial loss: 0.674393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195330; batch adversarial loss: 0.673542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.370339; batch adversarial loss: 0.699883\n",
      "epoch 44; iter: 0; batch classifier loss: 0.255854; batch adversarial loss: 0.662680\n",
      "epoch 45; iter: 0; batch classifier loss: 0.231286; batch adversarial loss: 0.688088\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207494; batch adversarial loss: 0.636396\n",
      "epoch 47; iter: 0; batch classifier loss: 0.196892; batch adversarial loss: 0.661115\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148754; batch adversarial loss: 0.625938\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125260; batch adversarial loss: 0.631144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x137ded6d8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_debiased_model.fit(dataset_transf_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_test = weighted_debiased_model.predict(dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.824746\n",
      "Test set: Balanced classification accuracy = 0.678085\n",
      "Test set: Disparate impact = 0.626986\n",
      "Test set: Equal opportunity difference = 0.016688\n",
      "Test set: Statistical parity difference = -0.063400\n",
      "Test set: Average odds difference = -0.001990\n",
      "Test set: Theil_index = 0.118844\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from model with debiasing\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_panel19_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_debiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End of Adv Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10.](#Table-of-Contents) SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_odds_diff</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>disp_imp</th>\n",
       "      <th>eq_opp_diff</th>\n",
       "      <th>stat_par_diff</th>\n",
       "      <th>theil_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bias Mitigator</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Training set</th>\n",
       "      <th>Testing set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel19</th>\n",
       "      <td>-0.205706</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.426176</td>\n",
       "      <td>-0.222779</td>\n",
       "      <td>-0.261207</td>\n",
       "      <td>0.092122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel19</th>\n",
       "      <td>-0.015104</td>\n",
       "      <td>0.753893</td>\n",
       "      <td>0.751755</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>-0.087196</td>\n",
       "      <td>0.096575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel20</th>\n",
       "      <td>0.007135</td>\n",
       "      <td>0.731136</td>\n",
       "      <td>0.805724</td>\n",
       "      <td>0.030262</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>0.101910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel21</th>\n",
       "      <td>-0.014340</td>\n",
       "      <td>0.737916</td>\n",
       "      <td>0.744126</td>\n",
       "      <td>-0.004405</td>\n",
       "      <td>-0.081262</td>\n",
       "      <td>0.099420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel20</th>\n",
       "      <th>Panel20</th>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.731345</td>\n",
       "      <td>0.825168</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.069257</td>\n",
       "      <td>0.096305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel20</th>\n",
       "      <th>Panel21</th>\n",
       "      <td>-0.010875</td>\n",
       "      <td>0.734998</td>\n",
       "      <td>0.809590</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>-0.075011</td>\n",
       "      <td>0.095536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             avg_odds_diff  \\\n",
       "Bias Mitigator Classifier          Training set Testing set                  \n",
       "               Logistic Regression Panel19      Panel19          -0.205706   \n",
       "Reweighing     Logistic Regression Panel19      Panel19          -0.015104   \n",
       "Reweighing     Logistic Regression Panel19      Panel20           0.007135   \n",
       "Reweighing     Logistic Regression Panel19      Panel21          -0.014340   \n",
       "Reweighing     Logistic Regression Panel20      Panel20           0.004045   \n",
       "Reweighing     Logistic Regression Panel20      Panel21          -0.010875   \n",
       "\n",
       "                                                              bal_acc  \\\n",
       "Bias Mitigator Classifier          Training set Testing set             \n",
       "               Logistic Regression Panel19      Panel19      0.775935   \n",
       "Reweighing     Logistic Regression Panel19      Panel19      0.753893   \n",
       "Reweighing     Logistic Regression Panel19      Panel20      0.731136   \n",
       "Reweighing     Logistic Regression Panel19      Panel21      0.737916   \n",
       "Reweighing     Logistic Regression Panel20      Panel20      0.731345   \n",
       "Reweighing     Logistic Regression Panel20      Panel21      0.734998   \n",
       "\n",
       "                                                             disp_imp  \\\n",
       "Bias Mitigator Classifier          Training set Testing set             \n",
       "               Logistic Regression Panel19      Panel19      0.426176   \n",
       "Reweighing     Logistic Regression Panel19      Panel19      0.751755   \n",
       "Reweighing     Logistic Regression Panel19      Panel20      0.805724   \n",
       "Reweighing     Logistic Regression Panel19      Panel21      0.744126   \n",
       "Reweighing     Logistic Regression Panel20      Panel20      0.825168   \n",
       "Reweighing     Logistic Regression Panel20      Panel21      0.809590   \n",
       "\n",
       "                                                             eq_opp_diff  \\\n",
       "Bias Mitigator Classifier          Training set Testing set                \n",
       "               Logistic Regression Panel19      Panel19        -0.222779   \n",
       "Reweighing     Logistic Regression Panel19      Panel19        -0.003518   \n",
       "Reweighing     Logistic Regression Panel19      Panel20         0.030262   \n",
       "Reweighing     Logistic Regression Panel19      Panel21        -0.004405   \n",
       "Reweighing     Logistic Regression Panel20      Panel20         0.041814   \n",
       "Reweighing     Logistic Regression Panel20      Panel21        -0.004093   \n",
       "\n",
       "                                                             stat_par_diff  \\\n",
       "Bias Mitigator Classifier          Training set Testing set                  \n",
       "               Logistic Regression Panel19      Panel19          -0.261207   \n",
       "Reweighing     Logistic Regression Panel19      Panel19          -0.087196   \n",
       "Reweighing     Logistic Regression Panel19      Panel20          -0.059602   \n",
       "Reweighing     Logistic Regression Panel19      Panel21          -0.081262   \n",
       "Reweighing     Logistic Regression Panel20      Panel20          -0.069257   \n",
       "Reweighing     Logistic Regression Panel20      Panel21          -0.075011   \n",
       "\n",
       "                                                             theil_ind  \n",
       "Bias Mitigator Classifier          Training set Testing set             \n",
       "               Logistic Regression Panel19      Panel19       0.092122  \n",
       "Reweighing     Logistic Regression Panel19      Panel19       0.096575  \n",
       "Reweighing     Logistic Regression Panel19      Panel20       0.101910  \n",
       "Reweighing     Logistic Regression Panel19      Panel21       0.099420  \n",
       "Reweighing     Logistic Regression Panel20      Panel20       0.096305  \n",
       "Reweighing     Logistic Regression Panel20      Panel21       0.095536  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [lr_orig_metrics, lr_transf_metrics,\n",
    "           lr_transf_metrics_panel20_deploy,\n",
    "           lr_transf_metrics_panel21_deploy,\n",
    "           lr_transf_metrics_panel20_test,\n",
    "           lr_transf_panel20_metrics_panel21_deploy]\n",
    "debias = pd.Series([''] + ['Reweighing']*5, name='Bias Mitigator')\n",
    "clf = pd.Series(['Logistic Regression']*6, name='Classifier')\n",
    "tr = pd.Series(['Panel19']*4 + ['Panel20']*2, name='Training set')\n",
    "te = pd.Series(['Panel19']*2 + ['Panel20', 'Panel21']*2, name='Testing set')\n",
    "pd.concat([pd.DataFrame(m) for m in results], axis=0).set_index([debias, clf, tr, te])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
