{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in healthcare utilization scoring model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Reference - https://nbviewer.jupyter.org/github/IBM/AIF360/blob/master/examples/tutorial_medical_expenditure.ipynb\n",
    "    </b>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This tutorial demonstrates classification model learning with bias mitigation as a part of a Care Management use case using Medical Expenditure data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook demonstrates how the AIF 360 toolkit can be used to detect and reduce bias when learning classifiers using a variety of fairness metrics and algorithms . It also demonstrates how explanations can be generated for predictions made by models learnt with the toolkit using LIME.\n",
    "\n",
    "Classifiers are built using Logistic Regression as well as Random Forests.\n",
    "\n",
    "Bias detection is demonstrated using several metrics, including disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index.\n",
    "\n",
    "Bias alleviation is explored via a variety of methods, including reweighing (pre-processing algorithm), prejudice remover (in-processing algorithm), and disparate impact remover (pre-processing technique).\n",
    "\n",
    "Data from the [Medical Expenditure Panel Survey](https://meps.ahrq.gov/mepsweb/) is used in this tutorial. See [Section 2](#2.-Data-used) below for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.](#Table-of-Contents) Use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to demonstrate how AIF 360 can be used to detect and mitigate bias in classfier models, we adopt the following use case:\n",
    "\n",
    "1. a data scientist develops a 'fair' healthcare utilization scoring model with respect to defined protected classes. Fairness may be dictated by legal or government regulations, such as a requirement that additional care decisions be not predicated on factors such as race of the patient.\n",
    "\n",
    "\n",
    "2. developer takes the model AND performance characteristics / specs of the model (e.g. accuracy, fairness tests, etc. basically the model factsheet) and deploys the model in an enterprise app that prioritizes cases for care management.\n",
    "\n",
    "\n",
    "3. the app is put into production and starts scoring people and making recommendations. \n",
    "\n",
    "\n",
    "4. explanations are generated for each recommendation\n",
    "\n",
    "\n",
    "5. both recommendations and associated explanations are given to nurses as a part of the care management process. The nurses can evaluate the recommendations for quality and correctness and provide feedback.\n",
    "\n",
    "\n",
    "6. nurse feedback as well as analysis of usage data with respect to specs of the model w.r.t accuracy and fairness is communicated to AI Ops specialist and LOB user periodically.\n",
    "\n",
    "\n",
    "7. when significant drift in model specs relative to the model factsheet is observed, the model is sent back for retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2.](#Table-of-Contents) Data used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "For this demonstration, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.](#Table-of-Contents) Training models on original 2015 Panel 19 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")),\n",
    "                                '..', 'data', 'raw', 'meps', 'h201.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dhanush/Documents/USC/Fall-2019/INF599/projects/AIF360/examples/../data/raw/meps/h201.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/dhanush/Documents/USC/Fall-2019/INF599/projects/AIF360/aif360/data/raw/meps/h201.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTSTU31X\n",
      "FTSTU42X\n",
      "FTSTU53X\n",
      "FTSTU17X\n"
     ]
    }
   ],
   "source": [
    "for s in df.columns.values:\n",
    "    if s.startswith('FTSTU'):\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTSTU\n",
      "ACTDTY\n",
      "HONRDC\n",
      "RTHLTH\n",
      "MNHLTH\n",
      "CHBRON\n",
      "JTPAIN\n",
      "PREGNT\n",
      "SOCLIM\n",
      "COGLIM\n"
     ]
    }
   ],
   "source": [
    "for col in ['FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX','EDUCYR','HIDEG',\n",
    "                     'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                     'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','SOCLIM','COGLIM','DFHEAR42','DFSEE42','ADSMOK42',\n",
    "                     'PHQ242']:\n",
    "    if col not in cols:\n",
    "        print(col)\n",
    "#         print(col in cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mappings = {\n",
    "    'label_maps': [{1.0: '>= 10 Visits', 0.0: '< 10 Visits'}],\n",
    "    'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-White'}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_preprocessing(df):\n",
    "    \"\"\"\n",
    "    1.Create a new column, RACE that is 'White' if RACEV2X = 1 and HISPANX = 2 i.e. non Hispanic White\n",
    "      and 'Non-White' otherwise\n",
    "    2. Restrict to Panel 21\n",
    "    3. RENAME all columns that are PANEL/ROUND SPECIFIC\n",
    "    4. Drop rows based on certain values of individual features that correspond to missing/unknown - generally < -1\n",
    "    5. Compute UTILIZATION, binarize it to 0 (< 10) and 1 (>= 10)\n",
    "    \"\"\"\n",
    "    def race(row):\n",
    "        if ((row['HISPANX'] == 2) and (row['RACEV2X'] == 1)):  #non-Hispanic Whites are marked as WHITE; all others as NON-WHITE\n",
    "            return 'White'\n",
    "        return 'Non-White'\n",
    "\n",
    "    df['RACEV2X'] = df.apply(lambda row: race(row), axis=1)\n",
    "    df = df.rename(columns = {'RACEV2X' : 'RACE'})\n",
    "\n",
    "    df = df[df['PANEL'] == 21]\n",
    "\n",
    "    # RENAME COLUMNS\n",
    "    df = df.rename(columns = {'FTSTU53X' : 'FTSTU', 'ACTDTY53' : 'ACTDTY', 'HONRDC53' : 'HONRDC', 'RTHLTH53' : 'RTHLTH',\n",
    "                              'MNHLTH53' : 'MNHLTH', 'CHBRON53' : 'CHBRON', 'JTPAIN53' : 'JTPAIN', 'PREGNT53' : 'PREGNT',\n",
    "                              'WLKLIM53' : 'WLKLIM', 'ACTLIM53' : 'ACTLIM', 'SOCLIM53' : 'SOCLIM', 'COGLIM53' : 'COGLIM',\n",
    "                              'EMPST53' : 'EMPST', 'REGION53' : 'REGION', 'MARRY53X' : 'MARRY', 'AGE53X' : 'AGE',\n",
    "                              'POVCAT16' : 'POVCAT', 'INSCOV16' : 'INSCOV'})\n",
    "\n",
    "    df = df[df['REGION'] >= 0] # remove values -1\n",
    "    df = df[df['AGE'] >= 0] # remove values -1\n",
    "\n",
    "    df = df[df['MARRY'] >= 0] # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[df['ASTHDX'] >= 0] # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[(df[['FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX','EDUCYR','HIDEG',\n",
    "                     'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                     'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','SOCLIM','COGLIM','DFHEAR42','DFSEE42','ADSMOK42',\n",
    "                     'PHQ242']] >= -1).all(1)]  #for all other categorical features, remove values < -1\n",
    "\n",
    "    def utilization(row):\n",
    "        return row['OBTOTV16'] + row['OPTOTV16'] + row['ERTOT16'] + row['IPNGTD16'] + row['HHTOTD16']\n",
    "\n",
    "    df['TOTEXP16'] = df.apply(lambda row: utilization(row), axis=1)\n",
    "    lessE = df['TOTEXP16'] < 10.0\n",
    "    df.loc[lessE,'TOTEXP16'] = 0.0\n",
    "    moreE = df['TOTEXP16'] >= 10.0\n",
    "    df.loc[moreE,'TOTEXP16'] = 1.0\n",
    "\n",
    "    df = df.rename(columns = {'TOTEXP16' : 'UTILIZATION'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name='UTILIZATION'\n",
    "favorable_classes=[1.0]\n",
    "protected_attribute_names=['RACE']\n",
    "privileged_classes=[['White']]\n",
    "instance_weights_name='PERWT16F'\n",
    "categorical_features=['REGION','SEX','MARRY', 'FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX',\n",
    "                      'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                      'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                      'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42', 'ADSMOK42', 'PHQ242',\n",
    "                      'EMPST','POVCAT','INSCOV']\n",
    "features_to_keep=['REGION','AGE','SEX','RACE','MARRY',\n",
    "                     'FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX',\n",
    "                     'MIDX','OHRTDX','STRKDX','EMPHDX','CHOLDX','CANCERDX','DIABDX',\n",
    "                     'ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','DFHEAR42','DFSEE42','ADSMOK42', 'PCS42',\n",
    "                     'MCS42','K6SUM42','PHQ242','EMPST','UTILIZATION', 'PERWT16F']\n",
    "features_to_drop=[]\n",
    "na_values=[]\n",
    "custom_preprocessing=default_preprocessing\n",
    "metadata=default_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"/Users/dhanush/Documents/USC/Fall-2019/INF599/projects/AIF360/aif360/data/raw/meps/h201.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath, sep=',', na_values=na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['WLKLIM', 'ACTLIM', 'COGLIM', 'JTPAIN', 'POVCAT', 'CHBRON', 'INSCOV', 'SOCLIM', 'PREGNT'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c15e305e3eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mfeatures_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mfeatures_to_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_to_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             custom_preprocessing=custom_preprocessing, metadata=metadata)\n\u001b[0m",
      "\u001b[0;32m~/Documents/USC/Fall-2019/INF599/projects/AIF360/aif360/datasets/standard_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, scores_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# 2. Perform dataset-specific preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcustom_preprocessing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# 3. Drop unrequested columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ca76f99df28a>\u001b[0m in \u001b[0;36mdefault_preprocessing\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     36\u001b[0m                              \u001b[0;34m'JTPAIN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ARTHDX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ARTHTYPE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ASTHDX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ADHDADDX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PREGNT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'WLKLIM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                              \u001b[0;34m'ACTLIM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SOCLIM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'COGLIM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DFHEAR42'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DFSEE42'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ADSMOK42'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                              'PHQ242','EMPST','POVCAT','INSCOV']] >= -1).all(1)]  #for all other categorical features, remove values < -1\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mutilization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['WLKLIM', 'ACTLIM', 'COGLIM', 'JTPAIN', 'POVCAT', 'CHBRON', 'INSCOV', 'SOCLIM', 'PREGNT'] not in index\""
     ]
    }
   ],
   "source": [
    "x = StandardDataset(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load data & create splits for learning/validating/testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset and split into train (70%), test (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aif360/datasets/standard_dataset.py:121: FutureWarning: outer method for ufunc <ufunc 'equal'> is not implemented on pandas objects. Returning an ndarray, but in the future this will raise a 'NotImplementedError'. Consider explicitly converting the Series to an array with '.array' first.\n",
      "  priv = np.logical_or.reduce(np.equal.outer(vals, df[attr]))\n"
     ]
    }
   ],
   "source": [
    "(dataset_orig_panel19_train,\n",
    " dataset_orig_panel19_test) = MEPSDataset21().split([0.7], shuffle=True)\n",
    "\n",
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "\n",
    "unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used throughout the notebook to print out some labels, names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def describe(train=None, val=None, test=None):\n",
    "    if train is not None:\n",
    "        display(Markdown(\"#### Training Dataset shape\"))\n",
    "        print(train.features.shape)\n",
    "    if val is not None:\n",
    "        display(Markdown(\"#### Validation Dataset shape\"))\n",
    "        print(val.features.shape)\n",
    "    display(Markdown(\"#### Test Dataset shape\"))\n",
    "    print(test.features.shape)\n",
    "    display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "    print(test.favorable_label, test.unfavorable_label)\n",
    "    display(Markdown(\"#### Protected attribute names\"))\n",
    "    print(test.protected_attribute_names)\n",
    "    display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "    print(test.privileged_protected_attributes, \n",
    "          test.unprivileged_protected_attributes)\n",
    "    display(Markdown(\"#### Dataset feature names\"))\n",
    "    print(test.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show 2015 dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10972, 138)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4703, 138)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RACE']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE', 'RACE', 'PCS42', 'MCS42', 'K6SUM42', 'REGION=1', 'REGION=2', 'REGION=3', 'REGION=4', 'SEX=1', 'SEX=2', 'MARRY=1', 'MARRY=2', 'MARRY=3', 'MARRY=4', 'MARRY=5', 'MARRY=6', 'MARRY=7', 'MARRY=8', 'MARRY=9', 'MARRY=10', 'FTSTU=-1', 'FTSTU=1', 'FTSTU=2', 'FTSTU=3', 'ACTDTY=1', 'ACTDTY=2', 'ACTDTY=3', 'ACTDTY=4', 'HONRDC=1', 'HONRDC=2', 'HONRDC=3', 'HONRDC=4', 'RTHLTH=-1', 'RTHLTH=1', 'RTHLTH=2', 'RTHLTH=3', 'RTHLTH=4', 'RTHLTH=5', 'MNHLTH=-1', 'MNHLTH=1', 'MNHLTH=2', 'MNHLTH=3', 'MNHLTH=4', 'MNHLTH=5', 'HIBPDX=-1', 'HIBPDX=1', 'HIBPDX=2', 'CHDDX=-1', 'CHDDX=1', 'CHDDX=2', 'ANGIDX=-1', 'ANGIDX=1', 'ANGIDX=2', 'MIDX=-1', 'MIDX=1', 'MIDX=2', 'OHRTDX=-1', 'OHRTDX=1', 'OHRTDX=2', 'STRKDX=-1', 'STRKDX=1', 'STRKDX=2', 'EMPHDX=-1', 'EMPHDX=1', 'EMPHDX=2', 'CHBRON=-1', 'CHBRON=1', 'CHBRON=2', 'CHOLDX=-1', 'CHOLDX=1', 'CHOLDX=2', 'CANCERDX=-1', 'CANCERDX=1', 'CANCERDX=2', 'DIABDX=-1', 'DIABDX=1', 'DIABDX=2', 'JTPAIN=-1', 'JTPAIN=1', 'JTPAIN=2', 'ARTHDX=-1', 'ARTHDX=1', 'ARTHDX=2', 'ARTHTYPE=-1', 'ARTHTYPE=1', 'ARTHTYPE=2', 'ARTHTYPE=3', 'ASTHDX=1', 'ASTHDX=2', 'ADHDADDX=-1', 'ADHDADDX=1', 'ADHDADDX=2', 'PREGNT=-1', 'PREGNT=1', 'PREGNT=2', 'WLKLIM=-1', 'WLKLIM=1', 'WLKLIM=2', 'ACTLIM=-1', 'ACTLIM=1', 'ACTLIM=2', 'SOCLIM=-1', 'SOCLIM=1', 'SOCLIM=2', 'COGLIM=-1', 'COGLIM=1', 'COGLIM=2', 'DFHEAR42=-1', 'DFHEAR42=1', 'DFHEAR42=2', 'DFSEE42=-1', 'DFSEE42=1', 'DFSEE42=2', 'ADSMOK42=-1', 'ADSMOK42=1', 'ADSMOK42=2', 'PHQ242=-1', 'PHQ242=0', 'PHQ242=1', 'PHQ242=2', 'PHQ242=3', 'PHQ242=4', 'PHQ242=5', 'PHQ242=6', 'EMPST=-1', 'EMPST=1', 'EMPST=2', 'EMPST=3', 'EMPST=4', 'POVCAT=1', 'POVCAT=2', 'POVCAT=3', 'POVCAT=4', 'POVCAT=5', 'INSCOV=1', 'INSCOV=2', 'INSCOV=3']\n"
     ]
    }
   ],
   "source": [
    "describe(dataset_orig_panel19_train, None, dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.4820224780986613\n"
     ]
    }
   ],
   "source": [
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "        dataset_orig_panel19_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)\n",
    "explainer_orig_panel19_train = MetricTextExplainer(metric_orig_panel19_train)\n",
    "\n",
    "print(explainer_orig_panel19_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Debiasing without debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.131976\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.115898\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_panel19_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_panel19_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.131976\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.115898\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_panel19_train.features = min_max_scaler.fit_transform(dataset_orig_panel19_train.features)\n",
    "dataset_orig_panel19_test.features = min_max_scaler.transform(dataset_orig_panel19_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_panel19_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_panel19_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.681122\n",
      "epoch 1; iter: 0; batch classifier loss: 0.376445\n",
      "epoch 2; iter: 0; batch classifier loss: 0.285735\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398125\n",
      "epoch 4; iter: 0; batch classifier loss: 0.225464\n",
      "epoch 5; iter: 0; batch classifier loss: 0.453644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348539\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433853\n",
      "epoch 8; iter: 0; batch classifier loss: 0.363735\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247386\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229941\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279161\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267856\n",
      "epoch 14; iter: 0; batch classifier loss: 0.178618\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314311\n",
      "epoch 17; iter: 0; batch classifier loss: 0.321154\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255264\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278132\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284294\n",
      "epoch 21; iter: 0; batch classifier loss: 0.330368\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230139\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231404\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270393\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303288\n",
      "epoch 27; iter: 0; batch classifier loss: 0.331838\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227993\n",
      "epoch 29; iter: 0; batch classifier loss: 0.282073\n",
      "epoch 30; iter: 0; batch classifier loss: 0.263790\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225764\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256087\n",
      "epoch 33; iter: 0; batch classifier loss: 0.319427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.218892\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293146\n",
      "epoch 36; iter: 0; batch classifier loss: 0.230185\n",
      "epoch 37; iter: 0; batch classifier loss: 0.251639\n",
      "epoch 38; iter: 0; batch classifier loss: 0.191726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.277673\n",
      "epoch 41; iter: 0; batch classifier loss: 0.257662\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249521\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207249\n",
      "epoch 44; iter: 0; batch classifier loss: 0.177597\n",
      "epoch 45; iter: 0; batch classifier loss: 0.228930\n",
      "epoch 46; iter: 0; batch classifier loss: 0.214488\n",
      "epoch 47; iter: 0; batch classifier loss: 0.173494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x133faf358>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.827398\n",
      "Test set: Balanced classification accuracy = 0.639508\n",
      "Test set: Disparate impact = 0.399601\n",
      "Test set: Equal opportunity difference = -0.144565\n",
      "Test set: Average odds difference = -0.096133\n",
      "Test set: Statistical parity difference = -0.092544\n",
      "Test set: Theil_index = 0.128564\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from model with debiasing\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_panel19_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_nodebiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Debiasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.131976\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.115898\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_panel19_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_panel19_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.131976\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.115898\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_panel19_train.features = min_max_scaler.fit_transform(dataset_orig_panel19_train.features)\n",
    "dataset_orig_panel19_test.features = min_max_scaler.transform(dataset_orig_panel19_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_panel19_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_panel19_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.488154; batch adversarial loss: 0.697556\n",
      "epoch 1; iter: 0; batch classifier loss: 0.284598; batch adversarial loss: 0.685454\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449048; batch adversarial loss: 0.690505\n",
      "epoch 3; iter: 0; batch classifier loss: 0.306396; batch adversarial loss: 0.661280\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363295; batch adversarial loss: 0.653064\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317632; batch adversarial loss: 0.675618\n",
      "epoch 6; iter: 0; batch classifier loss: 0.400940; batch adversarial loss: 0.661843\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361443; batch adversarial loss: 0.676482\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282645; batch adversarial loss: 0.636950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.264637; batch adversarial loss: 0.651169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.212423; batch adversarial loss: 0.635829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369639; batch adversarial loss: 0.651828\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330186; batch adversarial loss: 0.665263\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348576; batch adversarial loss: 0.662921\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260776; batch adversarial loss: 0.645337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377961; batch adversarial loss: 0.634072\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324466; batch adversarial loss: 0.626628\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259731; batch adversarial loss: 0.661519\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370327; batch adversarial loss: 0.651657\n",
      "epoch 19; iter: 0; batch classifier loss: 0.279584; batch adversarial loss: 0.683606\n",
      "epoch 20; iter: 0; batch classifier loss: 0.320095; batch adversarial loss: 0.663722\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282349; batch adversarial loss: 0.669680\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330237; batch adversarial loss: 0.729751\n",
      "epoch 23; iter: 0; batch classifier loss: 0.382477; batch adversarial loss: 0.649974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199398; batch adversarial loss: 0.634992\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237058; batch adversarial loss: 0.669257\n",
      "epoch 26; iter: 0; batch classifier loss: 0.219966; batch adversarial loss: 0.651426\n",
      "epoch 27; iter: 0; batch classifier loss: 0.311261; batch adversarial loss: 0.687570\n",
      "epoch 28; iter: 0; batch classifier loss: 0.258856; batch adversarial loss: 0.643071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281684; batch adversarial loss: 0.637025\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234938; batch adversarial loss: 0.655413\n",
      "epoch 31; iter: 0; batch classifier loss: 0.240428; batch adversarial loss: 0.670296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233143; batch adversarial loss: 0.653921\n",
      "epoch 33; iter: 0; batch classifier loss: 0.285968; batch adversarial loss: 0.662402\n",
      "epoch 34; iter: 0; batch classifier loss: 0.341455; batch adversarial loss: 0.655788\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251778; batch adversarial loss: 0.643989\n",
      "epoch 36; iter: 0; batch classifier loss: 0.254789; batch adversarial loss: 0.657366\n",
      "epoch 37; iter: 0; batch classifier loss: 0.369605; batch adversarial loss: 0.672326\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211216; batch adversarial loss: 0.618215\n",
      "epoch 39; iter: 0; batch classifier loss: 0.264737; batch adversarial loss: 0.674814\n",
      "epoch 40; iter: 0; batch classifier loss: 0.282311; batch adversarial loss: 0.642253\n",
      "epoch 41; iter: 0; batch classifier loss: 0.297998; batch adversarial loss: 0.662579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229874; batch adversarial loss: 0.682771\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237840; batch adversarial loss: 0.663473\n",
      "epoch 44; iter: 0; batch classifier loss: 0.205526; batch adversarial loss: 0.675118\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205687; batch adversarial loss: 0.679485\n",
      "epoch 46; iter: 0; batch classifier loss: 0.216286; batch adversarial loss: 0.659636\n",
      "epoch 47; iter: 0; batch classifier loss: 0.233497; batch adversarial loss: 0.656757\n",
      "epoch 48; iter: 0; batch classifier loss: 0.299771; batch adversarial loss: 0.685681\n",
      "epoch 49; iter: 0; batch classifier loss: 0.237289; batch adversarial loss: 0.658969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x13a20b978>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.829221\n",
      "Test set: Balanced classification accuracy = 0.596823\n",
      "Test set: Disparate impact = 1.254862\n",
      "Test set: Equal opportunity difference = 0.114900\n",
      "Test set: Average odds difference = 0.071529\n",
      "Test set: Statistical parity difference = 0.017232\n",
      "Test set: Theil_index = 0.135146\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from model with debiasing\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_panel19_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_debiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Debiasing with weighted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_panel19_train = RW.fit_transform(dataset_orig_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.000000\n"
     ]
    }
   ],
   "source": [
    "# Metric for the transformed dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_transf_panel19_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# Learn parameters with debias set to True\n",
    "weighted_debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706876; batch adversarial loss: 0.724897\n",
      "epoch 1; iter: 0; batch classifier loss: 0.267081; batch adversarial loss: 0.688839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.299851; batch adversarial loss: 0.692279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.277771; batch adversarial loss: 0.685785\n",
      "epoch 4; iter: 0; batch classifier loss: 0.292031; batch adversarial loss: 0.657146\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404674; batch adversarial loss: 0.645057\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328264; batch adversarial loss: 0.643620\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376575; batch adversarial loss: 0.664279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.264868; batch adversarial loss: 0.654066\n",
      "epoch 9; iter: 0; batch classifier loss: 0.382271; batch adversarial loss: 0.673713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288312; batch adversarial loss: 0.663045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358902; batch adversarial loss: 0.638753\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352823; batch adversarial loss: 0.648716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257049; batch adversarial loss: 0.678490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260459; batch adversarial loss: 0.669016\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243265; batch adversarial loss: 0.619634\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301618; batch adversarial loss: 0.634106\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355198; batch adversarial loss: 0.680691\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255643; batch adversarial loss: 0.643472\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250544; batch adversarial loss: 0.639949\n",
      "epoch 20; iter: 0; batch classifier loss: 0.297232; batch adversarial loss: 0.652268\n",
      "epoch 21; iter: 0; batch classifier loss: 0.373199; batch adversarial loss: 0.662457\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335049; batch adversarial loss: 0.634018\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287528; batch adversarial loss: 0.631981\n",
      "epoch 24; iter: 0; batch classifier loss: 0.291306; batch adversarial loss: 0.694170\n",
      "epoch 25; iter: 0; batch classifier loss: 0.251532; batch adversarial loss: 0.646729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297845; batch adversarial loss: 0.663336\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243212; batch adversarial loss: 0.656181\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375529; batch adversarial loss: 0.642899\n",
      "epoch 29; iter: 0; batch classifier loss: 0.288286; batch adversarial loss: 0.686294\n",
      "epoch 30; iter: 0; batch classifier loss: 0.383754; batch adversarial loss: 0.721381\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205005; batch adversarial loss: 0.626674\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230437; batch adversarial loss: 0.638480\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234705; batch adversarial loss: 0.662619\n",
      "epoch 34; iter: 0; batch classifier loss: 0.308112; batch adversarial loss: 0.654597\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257539; batch adversarial loss: 0.672169\n",
      "epoch 36; iter: 0; batch classifier loss: 0.232684; batch adversarial loss: 0.627310\n",
      "epoch 37; iter: 0; batch classifier loss: 0.245386; batch adversarial loss: 0.658800\n",
      "epoch 38; iter: 0; batch classifier loss: 0.323439; batch adversarial loss: 0.632638\n",
      "epoch 39; iter: 0; batch classifier loss: 0.248134; batch adversarial loss: 0.666871\n",
      "epoch 40; iter: 0; batch classifier loss: 0.244086; batch adversarial loss: 0.683466\n",
      "epoch 41; iter: 0; batch classifier loss: 0.249777; batch adversarial loss: 0.683406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.245096; batch adversarial loss: 0.671621\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220192; batch adversarial loss: 0.646147\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225720; batch adversarial loss: 0.616560\n",
      "epoch 45; iter: 0; batch classifier loss: 0.267364; batch adversarial loss: 0.667794\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324901; batch adversarial loss: 0.649980\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202523; batch adversarial loss: 0.645704\n",
      "epoch 48; iter: 0; batch classifier loss: 0.264756; batch adversarial loss: 0.690051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.242331; batch adversarial loss: 0.649290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x135e5d668>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_debiased_model.fit(dataset_transf_panel19_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_test = weighted_debiased_model.predict(dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - with weighted + debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.832999\n",
      "Test set: Balanced classification accuracy = 0.604049\n",
      "Test set: Disparate impact = 1.023957\n",
      "Test set: Equal opportunity difference = 0.091768\n",
      "Test set: Statistical parity difference = 0.001787\n",
      "Test set: Average odds difference = 0.053679\n",
      "Test set: Theil_index = 0.133067\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from model with debiasing\n",
    "\n",
    "display(Markdown(\"#### Model - with weighted + debiasing - classification metrics\"))\n",
    "classified_metric_weighted_debiasing_test = ClassificationMetric(dataset_orig_panel19_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_weighted_debiasing_test.accuracy())\n",
    "TPR = classified_metric_weighted_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_weighted_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_weighted_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_weighted_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_weighted_debiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_weighted_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_weighted_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equality of odds \n",
      "With Weighted + Debiasing\n",
      "0.030981145983376583 0.046572472080316826\n",
      "0.7768704393550616 0.6851028694534136\n",
      "\n",
      "With Debiasing\n",
      "0.027327885013855174 0.055485851503682536\n",
      "0.7952258799301948 0.6803255530258768\n",
      "\n",
      "Without Debiasing\n",
      "0.08738166664117543 0.03968100112631606\n",
      "0.6185764304283332 0.7631418948880946\n"
     ]
    }
   ],
   "source": [
    "# obeys equality of odds; the FNR and FPR values are approximately equal across sex subgroups\n",
    "print(\"Equality of odds \\nWith Weighted + Debiasing\")\n",
    "print(classified_metric_weighted_debiasing_test.false_positive_rate(True), \n",
    "      classified_metric_weighted_debiasing_test.false_positive_rate(False))\n",
    "print(classified_metric_weighted_debiasing_test.false_negative_rate(True), \n",
    "      classified_metric_weighted_debiasing_test.false_negative_rate(False))\n",
    "\n",
    "print(\"\\nWith Debiasing\")\n",
    "print(classified_metric_debiasing_test.false_positive_rate(True), \n",
    "      classified_metric_debiasing_test.false_positive_rate(False))\n",
    "print(classified_metric_debiasing_test.false_negative_rate(True), \n",
    "      classified_metric_debiasing_test.false_negative_rate(False))\n",
    "\n",
    "\n",
    "print(\"\\nWithout Debiasing\")\n",
    "print(classified_metric_nodebiasing_test.false_positive_rate(True), \n",
    "      classified_metric_nodebiasing_test.false_positive_rate(False))\n",
    "print(classified_metric_nodebiasing_test.false_negative_rate(True), \n",
    "      classified_metric_nodebiasing_test.false_negative_rate(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End of Adv Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10.](#Table-of-Contents) SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_odds_diff</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>disp_imp</th>\n",
       "      <th>eq_opp_diff</th>\n",
       "      <th>stat_par_diff</th>\n",
       "      <th>theil_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bias Mitigator</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Training set</th>\n",
       "      <th>Testing set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel19</th>\n",
       "      <td>-0.205706</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.426176</td>\n",
       "      <td>-0.222779</td>\n",
       "      <td>-0.261207</td>\n",
       "      <td>0.092122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel19</th>\n",
       "      <td>-0.015104</td>\n",
       "      <td>0.753893</td>\n",
       "      <td>0.751755</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>-0.087196</td>\n",
       "      <td>0.096575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel20</th>\n",
       "      <td>0.007135</td>\n",
       "      <td>0.731136</td>\n",
       "      <td>0.805724</td>\n",
       "      <td>0.030262</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>0.101910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel19</th>\n",
       "      <th>Panel21</th>\n",
       "      <td>-0.014340</td>\n",
       "      <td>0.737916</td>\n",
       "      <td>0.744126</td>\n",
       "      <td>-0.004405</td>\n",
       "      <td>-0.081262</td>\n",
       "      <td>0.099420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel20</th>\n",
       "      <th>Panel20</th>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.731345</td>\n",
       "      <td>0.825168</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.069257</td>\n",
       "      <td>0.096305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Panel20</th>\n",
       "      <th>Panel21</th>\n",
       "      <td>-0.010875</td>\n",
       "      <td>0.734998</td>\n",
       "      <td>0.809590</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>-0.075011</td>\n",
       "      <td>0.095536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             avg_odds_diff  \\\n",
       "Bias Mitigator Classifier          Training set Testing set                  \n",
       "               Logistic Regression Panel19      Panel19          -0.205706   \n",
       "Reweighing     Logistic Regression Panel19      Panel19          -0.015104   \n",
       "Reweighing     Logistic Regression Panel19      Panel20           0.007135   \n",
       "Reweighing     Logistic Regression Panel19      Panel21          -0.014340   \n",
       "Reweighing     Logistic Regression Panel20      Panel20           0.004045   \n",
       "Reweighing     Logistic Regression Panel20      Panel21          -0.010875   \n",
       "\n",
       "                                                              bal_acc  \\\n",
       "Bias Mitigator Classifier          Training set Testing set             \n",
       "               Logistic Regression Panel19      Panel19      0.775935   \n",
       "Reweighing     Logistic Regression Panel19      Panel19      0.753893   \n",
       "Reweighing     Logistic Regression Panel19      Panel20      0.731136   \n",
       "Reweighing     Logistic Regression Panel19      Panel21      0.737916   \n",
       "Reweighing     Logistic Regression Panel20      Panel20      0.731345   \n",
       "Reweighing     Logistic Regression Panel20      Panel21      0.734998   \n",
       "\n",
       "                                                             disp_imp  \\\n",
       "Bias Mitigator Classifier          Training set Testing set             \n",
       "               Logistic Regression Panel19      Panel19      0.426176   \n",
       "Reweighing     Logistic Regression Panel19      Panel19      0.751755   \n",
       "Reweighing     Logistic Regression Panel19      Panel20      0.805724   \n",
       "Reweighing     Logistic Regression Panel19      Panel21      0.744126   \n",
       "Reweighing     Logistic Regression Panel20      Panel20      0.825168   \n",
       "Reweighing     Logistic Regression Panel20      Panel21      0.809590   \n",
       "\n",
       "                                                             eq_opp_diff  \\\n",
       "Bias Mitigator Classifier          Training set Testing set                \n",
       "               Logistic Regression Panel19      Panel19        -0.222779   \n",
       "Reweighing     Logistic Regression Panel19      Panel19        -0.003518   \n",
       "Reweighing     Logistic Regression Panel19      Panel20         0.030262   \n",
       "Reweighing     Logistic Regression Panel19      Panel21        -0.004405   \n",
       "Reweighing     Logistic Regression Panel20      Panel20         0.041814   \n",
       "Reweighing     Logistic Regression Panel20      Panel21        -0.004093   \n",
       "\n",
       "                                                             stat_par_diff  \\\n",
       "Bias Mitigator Classifier          Training set Testing set                  \n",
       "               Logistic Regression Panel19      Panel19          -0.261207   \n",
       "Reweighing     Logistic Regression Panel19      Panel19          -0.087196   \n",
       "Reweighing     Logistic Regression Panel19      Panel20          -0.059602   \n",
       "Reweighing     Logistic Regression Panel19      Panel21          -0.081262   \n",
       "Reweighing     Logistic Regression Panel20      Panel20          -0.069257   \n",
       "Reweighing     Logistic Regression Panel20      Panel21          -0.075011   \n",
       "\n",
       "                                                             theil_ind  \n",
       "Bias Mitigator Classifier          Training set Testing set             \n",
       "               Logistic Regression Panel19      Panel19       0.092122  \n",
       "Reweighing     Logistic Regression Panel19      Panel19       0.096575  \n",
       "Reweighing     Logistic Regression Panel19      Panel20       0.101910  \n",
       "Reweighing     Logistic Regression Panel19      Panel21       0.099420  \n",
       "Reweighing     Logistic Regression Panel20      Panel20       0.096305  \n",
       "Reweighing     Logistic Regression Panel20      Panel21       0.095536  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [lr_orig_metrics, lr_transf_metrics,\n",
    "           lr_transf_metrics_panel20_deploy,\n",
    "           lr_transf_metrics_panel21_deploy,\n",
    "           lr_transf_metrics_panel20_test,\n",
    "           lr_transf_panel20_metrics_panel21_deploy]\n",
    "debias = pd.Series([''] + ['Reweighing']*5, name='Bias Mitigator')\n",
    "clf = pd.Series(['Logistic Regression']*6, name='Classifier')\n",
    "tr = pd.Series(['Panel19']*4 + ['Panel20']*2, name='Training set')\n",
    "te = pd.Series(['Panel19']*2 + ['Panel20', 'Panel21']*2, name='Testing set')\n",
    "pd.concat([pd.DataFrame(m) for m in results], axis=0).set_index([debias, clf, tr, te])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
